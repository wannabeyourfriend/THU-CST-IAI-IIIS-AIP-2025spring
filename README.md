# 拼音输入法 Lab Report

> 姓名：王子轩
>
> 学号：`2023011307`
>
>  邮箱：`wang-zx23@mails.tsinghua.edu.cn`

[TOC]

## 拼音输入法 

基于N元语言模型（一元、二元和三元）的拼音转汉字。能够通过统计语言模型，将拼音序列转换为最可能的汉字序列。

## 项目结构

```
Lab1/
│
├── src/                      # 源代码目录
│   ├── utils.py              # 工具函数，包含核心算法
│   └── train.py              # 训练模型相关函数
│
├── data/                     # 数据目录
│   ├── 拼音汉字表.txt         # 拼音到汉字的映射表
│   ├── 1_word.txt            # 训练好的一元模型
│   ├── 2_word.txt            # 训练好的二元模型
│   ├── 3_word.txt            # 训练好的三元模型（可选）
│   ├── input.txt             # 测试输入
│   └── answer.txt            # 测试标准答案
│
├── corpus/                   # 语料库目录
│   └── sina_news_gbk/        # 新浪新闻语料库
│
├── charts/                   # 图表输出目录（自动创建）
│
├── main.py                   # 主程序
└── README.md                 # 本文档
```


## 基本用法

可以按照以下流程检查作业

#### 对应作业中实验2的第一部分(30%) 二元模型性能检查

```bash
python main.py <data/input.txt >data/output.txt
# 训练、测试二元模型，运行这一行后，会在data文件夹下产生1_word.txt和2_word.txt文件两个模型，且可以在控制台看到本地测试的结果准确率，训练过程视cpu算力不同，本地运行数分钟
```

#### 对应作业中实验2的第二部分(10%) 扩展模型：三元模型

```bash
python main.py --train 3
# 先运行这一行后，会在data文件夹下产生3_word.txt文件，本地训练时间542.65秒
```

```bash
python main.py --trigram < data/input.txt > data/output.txt
# 运行这一行后，会在data文件夹下更新output.txt文件，且可以在控制台看到本地测试的结果准确率，训练过程视cpu算力不同有较大差异
```

系统会默认从头训练一元和二元模型并进行推断, 将结果重定向到output文档

## 自定义模式

```bash
# 训练所有模型（一元、二元和三元）
python main.py --train all

# 强制重新训练所有模型（忽略已有模型）
python main.py --train all --force-train

# 只训练特定模型 (1=一元, 2=二元, 3=三元)
python main.py --train <id>
```

默认情况下，系统使用二元模型。若要使用三元模型：

```bash
python main.py --trigram <data/input.txt > output.txt
```


三元模型中可以调整不同N元模型的权重（λ1, λ2, λ3）：

```bash
# 自定义权重 (λ1+λ2+λ3=1)
python main.py --trigram --lambda1 0.0 --lambda2 0.25 --lambda3 0.75 < data/input.txt > data/output.txt
```


搜索最佳的三元模型权重组合，并生成权重影响曲线图：

```bash
python main.py --trigram --grid-search
```

该命令会：

1. 对不同的权重组合进行测试
2. 找出字准确率和句准确率的最佳权重
3. 生成图表并保存至 `charts/` 目录
4. 将详细结果保存至 `charts/weight_search_results.txt`


对不同模型配置进行基准测试：

```bash
python main.py --benchmark
```

该命令会：

1. 测试二元模型和多种三元模型配置的性能
2. 计算各配置的平均处理时间和准确率
3. 将结果保存至 `data/benchmark_results.txt`


| 参数                  | 说明                                               |
| --------------------- | -------------------------------------------------- |
| `--trigram`           | 使用三元模型进行解码                               |
| `--train {1,2,3,all}` | 指定要训练的模型：1=一元, 2=二元, 3=三元, all=所有 |
| `--force-train`       | 强制重新训练已存在的模型                           |
| `--lambda1 FLOAT`     | 一元模型权重 (默认: 0.0)                           |
| `--lambda2 FLOAT`     | 二元模型权重 (默认: 0.5)                           |
| `--lambda3 FLOAT`     | 三元模型权重 (默认: 0.5)                           |
| `--grid-search`       | 执行权重网格搜索并绘制图表                         |
| `--benchmark`         | 运行性能基准测试                                   |


系统会自动分析并记录评测结果，包括：

1. **字准确率**：转换正确的汉字占总汉字数的比例
2. **句准确率**：完全正确转换的句子占总句子数的比例
3. **处理时间**：总处理时间和平均每行处理时间

结果会输出到：

- 控制台（stderr）
- `data/result.txt`
- `performance_log.txt`

## i. 实验环境

本实验在以下环境中进行：

- **操作系统**：Linux (Ubuntu 22.04)
- **编程语言**：Python 3.12
- **硬件配置**：
  - 16 vCPU Intel(R) Xeon(R) Platinum 8352V CPU @ 2.10GHz
  - 120GB内存

## ii. 语料库和数据预处理方法

### 使用的语料库

本实验使用了新浪新闻语料库（Sina News Corpus）作为训练数据。该语料库具有以下特点：

1. **规模**：包含大量新闻文本，覆盖多个领域
2. **格式**：GBK编码的纯文本文件
3. **内容**：现代汉语新闻文本，语言规范，代表性强

### 数据预处理方法

为了构建拼音输入法模型，我们对语料库进行了以下预处理步骤：

1. **字符过滤**：
   - 使用一二级汉字表作为合法汉字集合
   - 过滤掉非汉字字符（如标点符号、数字等）
   - 只保留在合法汉字集合中的字符用于统计

2. **拼音映射**：
   - 加载拼音汉字映射表，建立拼音到汉字的映射关系
   - 同时构建汉字到拼音的反向映射，用于模型训练和评估

3. **多进程并行处理**：
   - 使用Python的`ProcessPoolExecutor`进行多进程并行处理
   - 每个进程处理一个语料文件，提高处理效率

4. **频率统计**：
   - 对语料库中的汉字进行一元、二元和三元频率统计
   - 一元模型：统计单个汉字的出现频率
   - 二元模型：统计相邻两个汉字的共现频率
   - 三元模型：统计连续三个汉字的共现频率

5. **数据存储格式**：
   - 使用JSON格式存储模型数据
   - 按拼音组织数据，便于查询和使用

## iii. 基于字的二元模型的拼音输入法

### a 实验原理

#### a.1 基本思路

基于字的二元模型拼音输入法的基本思路是利用汉语中相邻汉字的统计规律来预测最可能的汉字序列。输入为拼音序列 $P = (p₁, p₂, …, pₙ)$，输出为最可能的汉字序列 $C = (c₁, c₂, …, cₖ)$。为了实现这一点，我们希望通过最大化条件概率 $P(C|P)$ 来找到最优的汉字序列。根据贝叶斯定理，我们有$P(C|P) \propto P(P|C) \times P(C)$ 由于拼音序列 $P$ 是已知的，我们的任务是最大化 $P(C)$，即寻找最可能的汉字序列。在二元模型中，假设当前汉字 $c_i$ 的出现只与其前一个汉字 $c_{i-1}$ 相关，而与其他汉字无关。这个假设即为马尔可夫假设，这是一种简单语言模型假设，因为它将对整个汉字序列的概率计算转化为对每一对相邻汉字的条件概率的乘积，从而减少了计算复杂度。为了从拼音序列中推测出最可能的汉字序列，采用维特比算法进行解码。使用动态规划的方式计算每个时间步的最优解。首先初始化：为每个拼音 $p_i$ 初始化候选汉字集合，候选汉字根据拼音的常见搭配进行排序。然后做递推：从左到右遍历拼音序列，对每个拼音 $pi$，利用前一个拼音对应的汉字序列，计算当前汉字序列的最大概率，结合二元模型的条件概率 $P(ci|c_{i-1})$。最后回溯，当遍历完成时，通过回溯找到最优的汉字序列。

#### a.2 公式推导

根据马尔可夫假设，一个字只依赖于其前一个字 $P(C) = P(c_1)\prod_{i=2}^n P(c_i|c_{i-1})$，为避免数值下溢，转换为对数概率 $\log P(C) = \log P(c_1) + \sum_{i=2}^n \log P(c_i|c_{i-1})$. 我们得到二元组条件概率的最大似然估计是 $P(c_i|c_{i-1}) = \frac{Count(c_{i-1}, c_i)}{Count(c_{i-1})}$ 为保证数值稳定性，使用平滑处理 $P(c_i|c_{i-1}) = \frac{Count(c_{i-1}, c_i) + 1}{Count(c_{i-1}) + |V|}$ 其中|V|是词汇表大小。定义$V[t][c]$为时刻$t$以字符$c$结尾的最大路径概率, 初始化 $V[1][c] = \log P(c)$ 写下递推公式为 $V[t][c] = \max_{c' \in C(t-1)} {V[t-1][c'] + \log P(c|c')}$ 其中$C(t-1)$是$t-1$时刻的候选字符集. 最优路径概率是 $P(C^*) = \max_{c \in C(n)} V[n][c]$ 从而最终优化目标可以表示为： $C^* = \arg\max_C {\log P(c_1) + \sum_{i=2}^n \log \frac{Count(c_{i-1}, c_i) + 1}{Count(c_{i-1}) + |V|}}$. 这个优化问题可以通过维特比算法在$\mathcal{O}(n × m²)$的时间复杂度内求解，其中n是序列长度，m是每个拼音对应的平均汉字数量。

#### a.3 算法原理

使用如下伪代码说明算法的具体步骤

```plain
1. Initialize bigram probabilities P(ci | ci-1)
2. For each pinyin in input P = (p1, p2, ..., pn):
    a. Generate possible characters for each pinyin (candidates)
    b. Sort candidates by likelihood (frequency or other metrics)
3. Initialize dp table:
    For i = 1 to n:
        For each candidate character ci for pi:
            dp[i][ci] = P(ci) if i == 1 else 0
4. Recursively fill dp table:
    For i = 2 to n:
        For each candidate ci for pi:
            For each candidate ci-1 for pi-1:
                prob = dp[i-1][ci-1] * P(ci | ci-1) * P(pi | ci)
                dp[i][ci] = max(dp[i][ci], prob)
5. Backtrack from dp[n][cn] to dp[1][c1] to find the best character sequence
6. Output the best sequence of characters
```

### b 实验效果

| 字准确率（给定样例）/ % | 句准确率（给定样例）/ % | 训练时间 / s | 推理时间（生成所有测例）/ s |
| ----------------------- | ----------------------- | ------------ | --------------------------- |
| 83.57                   | 38.72                   | 219.72       | 35.13                       |

*推理时间包括模型加载和输入处理推断两部分，这里的推理时间由6.02+5.87=11.89合计而成；原始数据如下

```txt
[2025-04-01 10:10:00] 程序启动参数: --benchmark
[2025-04-01 10:10:00] 所有需要的模型文件已存在，跳过训练步骤...
[2025-04-01 10:10:06] 模型加载完成！加载时间: 6.02秒
[2025-04-01 10:10:06] 开始运行性能基准测试...
[2025-04-01 10:10:06] 测试 二元模型...
[2025-04-01 10:10:12]   运行 1: 5.85秒
[2025-04-01 10:10:18]   运行 2: 5.84秒
[2025-04-01 10:10:24]   运行 3: 5.92秒
[2025-04-01 10:10:24]   平均时间: 5.87秒
[2025-04-01 10:10:24]   平均每行时间: 0.0117秒
[2025-04-01 10:10:24]   字准确率: 83.57%
[2025-04-01 10:10:24]   句准确率: 38.72%
[2025-04-01 10:10:24] 基准测试完成！结果已保存到 /mnt/d/Downloads/THU-CST-IAI-2025spring-master/THU-CST-IAI-2025spring-master/Lab1/data/benchmark_results.txt
```

### c 例子分析

| 正面例子                                                     | 负面例子                                                     |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| ji qi xue xi shi dang xia fei chang huo re de ji shu         | bei jing shi shou ge ju ban guo xia ao hui yu dong ao hui de cheng shi |
| 机器学习是当下非常火热的技术                                 | 北京市首个举办过夏奥会于冬奥会的城市（北京**是**首个举办过夏奥会与冬奥会的城市） |
| qing shan lv shui jiu shi jin shan yin shan                  | wei ji bai ke shi yi ge wang luo bai ke quan shu xiang mu    |
| 青山绿水就是金山银山                                         | 为几百克是一个网络百科全书项目（**维基百科**是一个网络百科全书项目） |
| zhong guo pin kun di qu shi xian wang luo fu wu quan fu gai  | zhong guo chen wen ying dui mao yi mo ca                     |
| 中国贫困地区实现网络服务全覆盖                               | 中国陈文应对贸易摩擦（中国**沉稳**应对贸易摩擦）             |
| yi qing mian qian zhong sai liang guo zai ci xie shou gong ke shi jian | chun feng hua yu le wei yang                                 |
| 疫情面前中塞两国在此携手共克时艰                             | 春风化娱乐为杨（春风**化雨乐未央**）                         |

二元模型输入法容易产生不准确或错误的原因主要在于其依赖于前一个词或字符的上下文，忽视了更长距离的依赖关系。这使得模型在处理复杂或长语境时容易产生错误。数据偏差也会导致模型过度依赖高频短语，忽略低频且实际存在的词组，从而导致错误的预测。此外，二元模型对稀有搭配和同音词处理较弱，可能会误将不常见的组合或同音词拼接错误，尤其在拼音输入法中，常见的拼音搭配错误更容易出现。模型的局限性还体现在它无法有效解决多义词的歧义问题，这使得它在处理含有多重含义的词语时产生不准确的结果。为提高准确性，需要引入更丰富的上下文信息和更复杂的模型结构，优化拼音词典，并通过平滑技术减少稀有词组合的影响。

## iv. 思考题

### a 语料编码

**GBK**是中文字符集GB2312的扩展，包含了简体和繁体中文字符，能够表示大部分中文字符，使用双字节（16位）来表示大多数汉字字符，因此它只能处理中国地区的字符。它的主要应用场景是在中国大陆的传统操作系统和程序中。而**UTF-8**是一种变长编码方式，能够表示全世界所有字符，支持超过100万个字符，包括中文、英文字母、阿拉伯文、日文等多种语言字符。UTF-8是Unicode的一部分，采用1到4个字节表示字符，具有较好的兼容性和跨平台特性。

**其他编码方式**：除了GBK和UTF-8外，还有ISO-8859-1（主要用于西欧语言的字符编码）和Big5（用于繁体中文的编码方式，主要在台湾地区使用）。这些编码方式各自有其应用场景，通常与语言的区域性有关

### b 算法设计

答案：
$$
时间复杂度: T(n,m) = \mathcal{O}(nm²)  \\
空间复杂度: S(n,m) ∈ \mathcal{O}(nm)
$$
状态转移计算：对于每个位置t (1 ≤ t ≤ n),遍历当前状态j ∈ [1, m],遍历前驱状态i ∈ [1, m]且每次计算涉及O(1)的转移概率和发射概率运算（因k为常数）。总时间复杂度：O(n) × O(m) × O(m) = **O(nm²)**。DP表存储：需要保存每个位置t每个状态j的最大概率，并用二维数组存储 → O(nm)。回溯指针存储：记录每个位置t每个状态j的最佳前驱，用二维数组存储 → O(nm)，所以总空间复杂度：O(nm) + O(nm) = **O(nm)**

### c 输入输出

代码A采用实时逐条输出策略，每次读取后立即打印，这种流式处理方式完全保持输入输出的时序一致性。代码B采用缓存批量输出策略，先缓存全部输入再统一输出，虽然改变了处理时序但最终输出顺序保持不变。在OJ评测系统采用全量输入/全量输出匹配模式的前提下，两种实现都能正确满足"原封不动输出"的要求，区别仅在于内存使用时机（代码B需要存储全部输入，而代码A不需要），因此两段代码均为正确实现。两种实现的终端输出示例已验证行为一致性。在OJ系统中实际评测时，系统会将所有输入一次性提供给程序，并最终比对全部输出结果，因此两种实现的实际评测效果完全相同。

## v. 在实验2中实现二元三元混合模型

#### 思路

二元模型(Bigram)：只考虑当前字与前一个字的关系，即$P(w_i|w_{i-1})$. 混合三元二元模型：同时考虑三元(Trigram)关系$P(w_i|w_{i-2},w_{i-1})$和二元关系。二元模型计算量较小，空间需求较少，混合模型计算量更大，但能捕捉更长的上下文依赖关系。我们采取插值法，将三元和二元模型按一定权重组合：$
λ₁P(w_i|w_{i-2},w_{i-1}) + λ₂P(w_i|w_{i-1}) + λ₃P(w_i)$ 。 混合模型在处理长句和复杂语境时有更好的准确率，我进行的实验结果如下所示，对于混合模型参数 ($λ1=0.0, λ2=0.3, λ3=0.7$)：

#### 结果

| 字准确率（给定样例）/ % | 句准确率（给定样例）/ % | 训练时间 / s | 推理时间（生成所有测例）/ s |
| ----------------------- | ----------------------- | ------------ | --------------------------- |
| 88.84                   | 55.09                   | 596.54       | 152.35                      |

*推理时间包括模型加载和测例答案生成

#### 比较

相比于单纯二元模型，我们的混合模型策略在两个准确率上均有提升，且在句子准确率上提升较大，说明三元模型的引入有助于捕捉长距离的语义信息。但是缺点是训练和推理速度均有所减慢。

原始数据：

```txt
[2025-04-01 18:40:30] 程序启动参数: --trigram --lambda1 0.0 --lambda2 0.3 --lambda3 0.7
[2025-04-01 18:40:30] 所有需要的模型文件已存在，跳过训练步骤...
[2025-04-01 18:42:52] 模型加载完成！加载时间: 141.34秒
[2025-04-01 18:42:52] 处理 501 行输入...
[2025-04-01 18:43:03] 推断完成！处理 501 行输入耗时: 11.01秒
[2025-04-01 18:43:03] 平均每行处理时间: 0.0220秒
[2025-04-01 18:43:03] 
评估结果：
[2025-04-01 18:43:03] 字准确率: 88.84%
[2025-04-01 18:43:03] 句准确率: 55.09%
[2025-04-01 18:43:03] 使用三元模型 (λ1=0.0, λ2=0.3, λ3=0.7)
[2025-04-01 18:43:03] 总运行时间: 152.35秒

```

## vi. 调节参数$\lambda_1, \lambda_2, \lambda_3$

$P(w_i) = \lambda_1P_1(w_i) + \lambda_2P_2(w_i | w_{i -1}) + \lambda_3 P_3(w_i | w_{i - 1}, w_{i -2})$

我们发现，设定$\lambda_1=0$是最佳选择

![image-20250401222117033](C:\Users\35551\Desktop\assets\image-20250401222117033.png)

原始数据如下：

```txt
Best character accuracy weights: λ1=0.0, λ2=0.4, λ3=0.6, Accuracy: 89.02%
Best sentence accuracy weights: λ1=0.0, λ2=0.3, λ3=0.7, Accuracy: 55.09%
Detailed results:
λ1,λ2,λ3,Character Accuracy,Sentence Accuracy
0.0,0.0,1.0,0.8252,0.5130
0.0,0.1,0.9,0.8785,0.5469
0.0,0.2,0.8,0.8846,0.5449
0.0,0.3,0.7,0.8884,0.5509
0.0,0.4,0.6,0.8902,0.5489
0.0,0.5,0.5,0.8875,0.5349
0.0,0.6,0.4,0.8829,0.5190
0.0,0.7,0.3,0.8756,0.4970
0.0,0.8,0.2,0.8617,0.4671
0.0,0.9,0.1,0.8460,0.4251
Grid search took: 123.85 seconds
```

根据实验数据和可视化结果，我们可以观察到混合语言模型中λ2参数对系统性能的显著影响。通过对字符准确率和句子准确率的双指标分析，发现当λ2取值在0.3到0.4之间时，模型性能达到最优水平，其中字符准确率最高可达89.02%（λ2=0.4），句子准确率最高可达55.09%（λ2=0.3）。这一现象反映了二元模型和三元模型在语言建模中的互补作用：纯三元模型（λ2=0）虽然能捕获更长的上下文依赖关系，但受限于训练数据的稀疏性；而随着二元模型权重的适度增加，系统能够更好地平衡长程依赖与数据充分性之间的关系，从而提升整体性能。然而，当λ2继续增大超过0.5后，模型性能开始显著下降，这表明过度依赖二元模型会损失重要的上下文信息。从曲线走势可以看出，两个评估指标虽然峰值位置略有差异，但都呈现出先升后降的趋势，这为模型参数的实际选择提供了重要的参考依据。

## viii. 感受与总结

这次实验总共耗时约30小时，时间分配上主要集中在三个方面：代码实现（5-10小时）、调试过程（15小时）以及参数优化与报告撰写（5小时）。调试阶段占用了最多时间。在实验环境方面，最初尝试在本地机器上运行，但在三元模型处理大量语料数据时候遇到了内存瓶颈。为解决这个问题，后续迁移到了AutoDL云平台上继续实验，显著提升了实验效率。这个经验表明，在进行大规模机器学习实验时，提前评估硬件需求非常重要。一些感受：

1. 建议在实验初期就评估计算资源需求，必要时直接使用云计算平台
2. 可以采用增量式开发策略，先用小规模数据集验证代码正确性，再扩展到完整数据集
3. 建议在代码中添加更多的日志和调试信息，这样可以更快定位问题
4. 参数调优阶段建议采用更系统的方法，比如网格搜索或贝叶斯优化

从实验结果来看，虽然调试过程耗时较长，但最终实现的混合语言模型取得了不错的效果，字符准确率和句子准确率都达到了预期水平。这个过程不仅加深了对语言模型的理解，也积累了宝贵的工程实践经验。
